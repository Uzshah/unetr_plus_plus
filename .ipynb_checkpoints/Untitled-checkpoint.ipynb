{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f38b1c52-5d54-4fea-9589-6f075b8c768d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unetr_pp.network_architecture.synapse.unetr_pp_synapse import UNETR_PP\n",
    "\n",
    "\n",
    "model = UNETR_PP(in_channels=1,\n",
    "                 out_channels=14,\n",
    "                 img_size=[64, 128, 128],\n",
    "                 feature_size=16,\n",
    "                 num_heads=4,\n",
    "                 depths=[3, 3, 3, 3],\n",
    "                 dims=[32, 64, 128, 256],\n",
    "                 do_ds=True,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cc020af-0c6d-4a45-91d7-d8550a76c62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| module                                  | #parameters or shape   | #flops     |\n",
      "|:----------------------------------------|:-----------------------|:-----------|\n",
      "| model                                   | 42.953M                | 47.936G    |\n",
      "|  unetr_pp_encoder                       |  27.387M               |  12.703G   |\n",
      "|   unetr_pp_encoder.downsample_layers    |   0.346M               |   0.158G   |\n",
      "|    unetr_pp_encoder.downsample_layers.0 |    1.088K              |    38.797M |\n",
      "|    unetr_pp_encoder.downsample_layers.1 |    16.512K             |    68.42M  |\n",
      "|    unetr_pp_encoder.downsample_layers.2 |    65.792K             |    33.882M |\n",
      "|    unetr_pp_encoder.downsample_layers.3 |    0.263M              |    16.859M |\n",
      "|   unetr_pp_encoder.stages               |   27.041M              |   12.545G  |\n",
      "|    unetr_pp_encoder.stages.0            |    9.623M              |    6.943G  |\n",
      "|    unetr_pp_encoder.stages.1            |    2.312M              |    3.258G  |\n",
      "|    unetr_pp_encoder.stages.2            |    3.248M              |    1.576G  |\n",
      "|    unetr_pp_encoder.stages.3            |    11.859M             |    0.768G  |\n",
      "|  encoder1                               |  7.36K                 |  7.919G    |\n",
      "|   encoder1.conv1.conv                   |   0.432K               |   0.453G   |\n",
      "|    encoder1.conv1.conv.weight           |    (16, 1, 3, 3, 3)    |            |\n",
      "|   encoder1.conv2.conv                   |   6.912K               |   7.248G   |\n",
      "|    encoder1.conv2.conv.weight           |    (16, 16, 3, 3, 3)   |            |\n",
      "|   encoder1.conv3.conv                   |   16                   |   16.777M  |\n",
      "|    encoder1.conv3.conv.weight           |    (16, 1, 1, 1, 1)    |            |\n",
      "|   encoder1.norm1                        |                        |   67.109M  |\n",
      "|   encoder1.norm2                        |                        |   67.109M  |\n",
      "|   encoder1.norm3                        |                        |   67.109M  |\n",
      "|  decoder5                               |  3.51M                 |  1.593G    |\n",
      "|   decoder5.transp_conv.conv             |   0.262M               |   16.777M  |\n",
      "|    decoder5.transp_conv.conv.weight     |    (256, 128, 2, 2, 2) |            |\n",
      "|   decoder5.decoder_block.0              |   3.248M               |   1.576G   |\n",
      "|    decoder5.decoder_block.0.0           |    1.083M              |    0.525G  |\n",
      "|    decoder5.decoder_block.0.1           |    1.083M              |    0.525G  |\n",
      "|    decoder5.decoder_block.0.2           |    1.083M              |    0.525G  |\n",
      "|  decoder4                               |  2.378M                |  3.292G    |\n",
      "|   decoder4.transp_conv.conv             |   65.536K              |   33.554M  |\n",
      "|    decoder4.transp_conv.conv.weight     |    (128, 64, 2, 2, 2)  |            |\n",
      "|   decoder4.decoder_block.0              |   2.312M               |   3.258G   |\n",
      "|    decoder4.decoder_block.0.0           |    0.771M              |    1.086G  |\n",
      "|    decoder4.decoder_block.0.1           |    0.771M              |    1.086G  |\n",
      "|    decoder4.decoder_block.0.2           |    0.771M              |    1.086G  |\n",
      "|  decoder3                               |  9.639M                |  7.01G     |\n",
      "|   decoder3.transp_conv.conv             |   16.384K              |   67.109M  |\n",
      "|    decoder3.transp_conv.conv.weight     |    (64, 32, 2, 2, 2)   |            |\n",
      "|   decoder3.decoder_block.0              |   9.623M               |   6.943G   |\n",
      "|    decoder3.decoder_block.0.0           |    3.208M              |    2.314G  |\n",
      "|    decoder3.decoder_block.0.1           |    3.208M              |    2.314G  |\n",
      "|    decoder3.decoder_block.0.2           |    3.208M              |    2.314G  |\n",
      "|  decoder2                               |  30.208K               |  15.167G   |\n",
      "|   decoder2.transp_conv.conv             |   16.384K              |   0.537G   |\n",
      "|    decoder2.transp_conv.conv.weight     |    (32, 16, 2, 4, 4)   |            |\n",
      "|   decoder2.decoder_block.0              |   13.824K              |   14.63G   |\n",
      "|    decoder2.decoder_block.0.conv1.conv  |    6.912K              |    7.248G  |\n",
      "|    decoder2.decoder_block.0.conv2.conv  |    6.912K              |    7.248G  |\n",
      "|    decoder2.decoder_block.0.norm1       |                        |    67.109M |\n",
      "|    decoder2.decoder_block.0.norm2       |                        |    67.109M |\n",
      "|  out1.conv.conv                         |  0.238K                |  0.235G    |\n",
      "|   out1.conv.conv.weight                 |   (14, 16, 1, 1, 1)    |            |\n",
      "|   out1.conv.conv.bias                   |   (14,)                |            |\n",
      "|  out2.conv.conv                         |  0.462K                |  14.68M    |\n",
      "|   out2.conv.conv.weight                 |   (14, 32, 1, 1, 1)    |            |\n",
      "|   out2.conv.conv.bias                   |   (14,)                |            |\n",
      "|  out3.conv.conv                         |  0.91K                 |  3.67M     |\n",
      "|   out3.conv.conv.weight                 |   (14, 64, 1, 1, 1)    |            |\n",
      "|   out3.conv.conv.bias                   |   (14,)                |            |\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from fvcore.nn import FlopCountAnalysis, flop_count_table\n",
    "\n",
    "input = torch.randn((1, 1, 64, 128, 128))\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a7951e5-cb08-44df-b019-cb944a821c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| module                                  | #parameters or shape   | #flops     |\n",
      "|:----------------------------------------|:-----------------------|:-----------|\n",
      "| model                                   | 19.983M                | 46.223G    |\n",
      "|  unetr_pp_encoder                       |  15.779M               |  11.838G   |\n",
      "|   unetr_pp_encoder.downsample_layers    |   0.346M               |   0.158G   |\n",
      "|    unetr_pp_encoder.downsample_layers.0 |    1.088K              |    38.797M |\n",
      "|    unetr_pp_encoder.downsample_layers.1 |    16.512K             |    68.42M  |\n",
      "|    unetr_pp_encoder.downsample_layers.2 |    65.792K             |    33.882M |\n",
      "|    unetr_pp_encoder.downsample_layers.3 |    0.263M              |    16.859M |\n",
      "|   unetr_pp_encoder.stages               |   15.432M              |   11.68G   |\n",
      "|    unetr_pp_encoder.stages.0            |    0.186M              |    6.37G   |\n",
      "|    unetr_pp_encoder.stages.1            |    0.729M              |    3.052G  |\n",
      "|    unetr_pp_encoder.stages.2            |    2.906M              |    1.507G  |\n",
      "|    unetr_pp_encoder.stages.3            |    11.611M             |    0.751G  |\n",
      "|  encoder1                               |  7.36K                 |  7.919G    |\n",
      "|   encoder1.conv1.conv                   |   0.432K               |   0.453G   |\n",
      "|    encoder1.conv1.conv.weight           |    (16, 1, 3, 3, 3)    |            |\n",
      "|   encoder1.conv2.conv                   |   6.912K               |   7.248G   |\n",
      "|    encoder1.conv2.conv.weight           |    (16, 16, 3, 3, 3)   |            |\n",
      "|   encoder1.conv3.conv                   |   16                   |   16.777M  |\n",
      "|    encoder1.conv3.conv.weight           |    (16, 1, 1, 1, 1)    |            |\n",
      "|   encoder1.norm1                        |                        |   67.109M  |\n",
      "|   encoder1.norm2                        |                        |   67.109M  |\n",
      "|   encoder1.norm3                        |                        |   67.109M  |\n",
      "|  decoder5                               |  3.168M                |  1.524G    |\n",
      "|   decoder5.transp_conv.conv             |   0.262M               |   16.777M  |\n",
      "|    decoder5.transp_conv.conv.weight     |    (256, 128, 2, 2, 2) |            |\n",
      "|   decoder5.decoder_block.0              |   2.906M               |   1.507G   |\n",
      "|    decoder5.decoder_block.0.0           |    0.969M              |    0.502G  |\n",
      "|    decoder5.decoder_block.0.1           |    0.969M              |    0.502G  |\n",
      "|    decoder5.decoder_block.0.2           |    0.969M              |    0.502G  |\n",
      "|  decoder4                               |  0.794M                |  3.086G    |\n",
      "|   decoder4.transp_conv.conv             |   65.536K              |   33.554M  |\n",
      "|    decoder4.transp_conv.conv.weight     |    (128, 64, 2, 2, 2)  |            |\n",
      "|   decoder4.decoder_block.0              |   0.729M               |   3.052G   |\n",
      "|    decoder4.decoder_block.0.0           |    0.243M              |    1.017G  |\n",
      "|    decoder4.decoder_block.0.1           |    0.243M              |    1.017G  |\n",
      "|    decoder4.decoder_block.0.2           |    0.243M              |    1.017G  |\n",
      "|  decoder3                               |  0.203M                |  6.437G    |\n",
      "|   decoder3.transp_conv.conv             |   16.384K              |   67.109M  |\n",
      "|    decoder3.transp_conv.conv.weight     |    (64, 32, 2, 2, 2)   |            |\n",
      "|   decoder3.decoder_block.0              |   0.186M               |   6.37G    |\n",
      "|    decoder3.decoder_block.0.0           |    62.049K             |    2.123G  |\n",
      "|    decoder3.decoder_block.0.1           |    62.049K             |    2.123G  |\n",
      "|    decoder3.decoder_block.0.2           |    62.049K             |    2.123G  |\n",
      "|  decoder2                               |  30.208K               |  15.167G   |\n",
      "|   decoder2.transp_conv.conv             |   16.384K              |   0.537G   |\n",
      "|    decoder2.transp_conv.conv.weight     |    (32, 16, 2, 4, 4)   |            |\n",
      "|   decoder2.decoder_block.0              |   13.824K              |   14.63G   |\n",
      "|    decoder2.decoder_block.0.conv1.conv  |    6.912K              |    7.248G  |\n",
      "|    decoder2.decoder_block.0.conv2.conv  |    6.912K              |    7.248G  |\n",
      "|    decoder2.decoder_block.0.norm1       |                        |    67.109M |\n",
      "|    decoder2.decoder_block.0.norm2       |                        |    67.109M |\n",
      "|  out1.conv.conv                         |  0.238K                |  0.235G    |\n",
      "|   out1.conv.conv.weight                 |   (14, 16, 1, 1, 1)    |            |\n",
      "|   out1.conv.conv.bias                   |   (14,)                |            |\n",
      "|  out2.conv.conv                         |  0.462K                |  14.68M    |\n",
      "|   out2.conv.conv.weight                 |   (14, 32, 1, 1, 1)    |            |\n",
      "|   out2.conv.conv.bias                   |   (14,)                |            |\n",
      "|  out3.conv.conv                         |  0.91K                 |  3.67M     |\n",
      "|   out3.conv.conv.weight                 |   (14, 64, 1, 1, 1)    |            |\n",
      "|   out3.conv.conv.bias                   |   (14,)                |            |\n"
     ]
    }
   ],
   "source": [
    "from unetr_pp.network_architecture.synapse.unetr_pp_synapse import UNETR_PP\n",
    "\n",
    "\n",
    "model = UNETR_PP(in_channels=1,\n",
    "                 out_channels=14,\n",
    "                 img_size=[64, 128, 128],\n",
    "                 feature_size=16,\n",
    "                 num_heads=4,\n",
    "                 depths=[3, 3, 3, 3],\n",
    "                 dims=[32, 64, 128, 256],\n",
    "                 do_ds=True,\n",
    "                 )\n",
    "\n",
    "import torch\n",
    "from fvcore.nn import FlopCountAnalysis, flop_count_table\n",
    "\n",
    "input = torch.randn((1, 1, 64, 128, 128))\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaf3d3bd-c56b-4137-86fa-f72ee85a7cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNETR_PP(\n",
       "  (unetr_pp_encoder): UnetrPPEncoder(\n",
       "    (downsample_layers): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Convolution(\n",
       "          (conv): Conv3d(1, 32, kernel_size=(2, 4, 4), stride=(2, 4, 4), bias=False)\n",
       "        )\n",
       "        (1): GroupNorm(1, 32, eps=1e-05, affine=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Convolution(\n",
       "          (conv): Conv3d(32, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "        )\n",
       "        (1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Convolution(\n",
       "          (conv): Conv3d(64, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "        )\n",
       "        (1): GroupNorm(64, 128, eps=1e-05, affine=True)\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): Convolution(\n",
       "          (conv): Conv3d(128, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "        )\n",
       "        (1): GroupNorm(128, 256, eps=1e-05, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (stages): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): TransformerBlock(\n",
       "          (norm): GroupNorm(1, 32, eps=1e-05, affine=True)\n",
       "          (ecd_block): ECD(\n",
       "            (content_kv): Linear(in_features=32, out_features=64, bias=False)\n",
       "            (semantic_query): Linear(in_features=32, out_features=32, bias=False)\n",
       "            (geometric_query): Linear(in_features=32, out_features=32, bias=False)\n",
       "            (semantic_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "            (semantic_projection): Linear(in_features=32, out_features=16, bias=True)\n",
       "            (geometric_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "            (geometric_projection): Linear(in_features=32, out_features=16, bias=True)\n",
       "            (semantic_dropout): Dropout(p=0.15, inplace=False)\n",
       "            (geometric_dropout): Dropout(p=0.15, inplace=False)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(32, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (norm): GroupNorm(1, 32, eps=1e-05, affine=True)\n",
       "          (ecd_block): ECD(\n",
       "            (content_kv): Linear(in_features=32, out_features=64, bias=False)\n",
       "            (semantic_query): Linear(in_features=32, out_features=32, bias=False)\n",
       "            (geometric_query): Linear(in_features=32, out_features=32, bias=False)\n",
       "            (semantic_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "            (semantic_projection): Linear(in_features=32, out_features=16, bias=True)\n",
       "            (geometric_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "            (geometric_projection): Linear(in_features=32, out_features=16, bias=True)\n",
       "            (semantic_dropout): Dropout(p=0.15, inplace=False)\n",
       "            (geometric_dropout): Dropout(p=0.15, inplace=False)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(32, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (norm): GroupNorm(1, 32, eps=1e-05, affine=True)\n",
       "          (ecd_block): ECD(\n",
       "            (content_kv): Linear(in_features=32, out_features=64, bias=False)\n",
       "            (semantic_query): Linear(in_features=32, out_features=32, bias=False)\n",
       "            (geometric_query): Linear(in_features=32, out_features=32, bias=False)\n",
       "            (semantic_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "            (semantic_projection): Linear(in_features=32, out_features=16, bias=True)\n",
       "            (geometric_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "            (geometric_projection): Linear(in_features=32, out_features=16, bias=True)\n",
       "            (semantic_dropout): Dropout(p=0.15, inplace=False)\n",
       "            (geometric_dropout): Dropout(p=0.15, inplace=False)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(32, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): TransformerBlock(\n",
       "          (norm): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "          (ecd_block): ECD(\n",
       "            (content_kv): Linear(in_features=64, out_features=128, bias=False)\n",
       "            (semantic_query): Linear(in_features=64, out_features=64, bias=False)\n",
       "            (geometric_query): Linear(in_features=16, out_features=16, bias=False)\n",
       "            (semantic_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            (semantic_projection): Linear(in_features=64, out_features=32, bias=True)\n",
       "            (geometric_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            (geometric_projection): Linear(in_features=64, out_features=32, bias=True)\n",
       "            (semantic_dropout): Dropout(p=0.15, inplace=False)\n",
       "            (geometric_dropout): Dropout(p=0.15, inplace=False)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (norm): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "          (ecd_block): ECD(\n",
       "            (content_kv): Linear(in_features=64, out_features=128, bias=False)\n",
       "            (semantic_query): Linear(in_features=64, out_features=64, bias=False)\n",
       "            (geometric_query): Linear(in_features=16, out_features=16, bias=False)\n",
       "            (semantic_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            (semantic_projection): Linear(in_features=64, out_features=32, bias=True)\n",
       "            (geometric_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            (geometric_projection): Linear(in_features=64, out_features=32, bias=True)\n",
       "            (semantic_dropout): Dropout(p=0.15, inplace=False)\n",
       "            (geometric_dropout): Dropout(p=0.15, inplace=False)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (norm): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "          (ecd_block): ECD(\n",
       "            (content_kv): Linear(in_features=64, out_features=128, bias=False)\n",
       "            (semantic_query): Linear(in_features=64, out_features=64, bias=False)\n",
       "            (geometric_query): Linear(in_features=16, out_features=16, bias=False)\n",
       "            (semantic_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            (semantic_projection): Linear(in_features=64, out_features=32, bias=True)\n",
       "            (geometric_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            (geometric_projection): Linear(in_features=64, out_features=32, bias=True)\n",
       "            (semantic_dropout): Dropout(p=0.15, inplace=False)\n",
       "            (geometric_dropout): Dropout(p=0.15, inplace=False)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): TransformerBlock(\n",
       "          (norm): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "          (ecd_block): ECD(\n",
       "            (content_kv): Linear(in_features=128, out_features=256, bias=False)\n",
       "            (semantic_query): Linear(in_features=128, out_features=128, bias=False)\n",
       "            (geometric_query): Linear(in_features=8, out_features=8, bias=False)\n",
       "            (semantic_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (semantic_projection): Linear(in_features=128, out_features=64, bias=True)\n",
       "            (geometric_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (geometric_projection): Linear(in_features=128, out_features=64, bias=True)\n",
       "            (semantic_dropout): Dropout(p=0.15, inplace=False)\n",
       "            (geometric_dropout): Dropout(p=0.15, inplace=False)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (norm): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "          (ecd_block): ECD(\n",
       "            (content_kv): Linear(in_features=128, out_features=256, bias=False)\n",
       "            (semantic_query): Linear(in_features=128, out_features=128, bias=False)\n",
       "            (geometric_query): Linear(in_features=8, out_features=8, bias=False)\n",
       "            (semantic_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (semantic_projection): Linear(in_features=128, out_features=64, bias=True)\n",
       "            (geometric_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (geometric_projection): Linear(in_features=128, out_features=64, bias=True)\n",
       "            (semantic_dropout): Dropout(p=0.15, inplace=False)\n",
       "            (geometric_dropout): Dropout(p=0.15, inplace=False)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (norm): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "          (ecd_block): ECD(\n",
       "            (content_kv): Linear(in_features=128, out_features=256, bias=False)\n",
       "            (semantic_query): Linear(in_features=128, out_features=128, bias=False)\n",
       "            (geometric_query): Linear(in_features=8, out_features=8, bias=False)\n",
       "            (semantic_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (semantic_projection): Linear(in_features=128, out_features=64, bias=True)\n",
       "            (geometric_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (geometric_projection): Linear(in_features=128, out_features=64, bias=True)\n",
       "            (semantic_dropout): Dropout(p=0.15, inplace=False)\n",
       "            (geometric_dropout): Dropout(p=0.15, inplace=False)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): TransformerBlock(\n",
       "          (norm): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
       "          (ecd_block): ECD(\n",
       "            (content_kv): Linear(in_features=256, out_features=512, bias=False)\n",
       "            (semantic_query): Linear(in_features=256, out_features=256, bias=False)\n",
       "            (geometric_query): Linear(in_features=4, out_features=4, bias=False)\n",
       "            (semantic_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (semantic_projection): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (geometric_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (geometric_projection): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (semantic_dropout): Dropout(p=0.15, inplace=False)\n",
       "            (geometric_dropout): Dropout(p=0.15, inplace=False)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (norm): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
       "          (ecd_block): ECD(\n",
       "            (content_kv): Linear(in_features=256, out_features=512, bias=False)\n",
       "            (semantic_query): Linear(in_features=256, out_features=256, bias=False)\n",
       "            (geometric_query): Linear(in_features=4, out_features=4, bias=False)\n",
       "            (semantic_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (semantic_projection): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (geometric_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (geometric_projection): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (semantic_dropout): Dropout(p=0.15, inplace=False)\n",
       "            (geometric_dropout): Dropout(p=0.15, inplace=False)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (norm): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
       "          (ecd_block): ECD(\n",
       "            (content_kv): Linear(in_features=256, out_features=512, bias=False)\n",
       "            (semantic_query): Linear(in_features=256, out_features=256, bias=False)\n",
       "            (geometric_query): Linear(in_features=4, out_features=4, bias=False)\n",
       "            (semantic_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (semantic_projection): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (geometric_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (geometric_projection): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (semantic_dropout): Dropout(p=0.15, inplace=False)\n",
       "            (geometric_dropout): Dropout(p=0.15, inplace=False)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoder1): UnetResBlock(\n",
       "    (conv1): Convolution(\n",
       "      (conv): Conv3d(1, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    )\n",
       "    (conv2): Convolution(\n",
       "      (conv): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    )\n",
       "    (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (norm1): InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (norm2): InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (conv3): Convolution(\n",
       "      (conv): Conv3d(1, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "    )\n",
       "    (norm3): InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "  )\n",
       "  (decoder5): UnetrUpBlock(\n",
       "    (transp_conv): Convolution(\n",
       "      (conv): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "    )\n",
       "    (decoder_block): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): TransformerBlock(\n",
       "          (norm): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "          (ecd_block): ECD(\n",
       "            (content_kv): Linear(in_features=128, out_features=256, bias=False)\n",
       "            (semantic_query): Linear(in_features=128, out_features=128, bias=False)\n",
       "            (geometric_query): Linear(in_features=8, out_features=8, bias=False)\n",
       "            (semantic_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (semantic_projection): Linear(in_features=128, out_features=64, bias=True)\n",
       "            (geometric_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (geometric_projection): Linear(in_features=128, out_features=64, bias=True)\n",
       "            (semantic_dropout): Dropout(p=0.15, inplace=False)\n",
       "            (geometric_dropout): Dropout(p=0.15, inplace=False)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (norm): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "          (ecd_block): ECD(\n",
       "            (content_kv): Linear(in_features=128, out_features=256, bias=False)\n",
       "            (semantic_query): Linear(in_features=128, out_features=128, bias=False)\n",
       "            (geometric_query): Linear(in_features=8, out_features=8, bias=False)\n",
       "            (semantic_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (semantic_projection): Linear(in_features=128, out_features=64, bias=True)\n",
       "            (geometric_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (geometric_projection): Linear(in_features=128, out_features=64, bias=True)\n",
       "            (semantic_dropout): Dropout(p=0.15, inplace=False)\n",
       "            (geometric_dropout): Dropout(p=0.15, inplace=False)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (norm): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "          (ecd_block): ECD(\n",
       "            (content_kv): Linear(in_features=128, out_features=256, bias=False)\n",
       "            (semantic_query): Linear(in_features=128, out_features=128, bias=False)\n",
       "            (geometric_query): Linear(in_features=8, out_features=8, bias=False)\n",
       "            (semantic_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (semantic_projection): Linear(in_features=128, out_features=64, bias=True)\n",
       "            (geometric_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (geometric_projection): Linear(in_features=128, out_features=64, bias=True)\n",
       "            (semantic_dropout): Dropout(p=0.15, inplace=False)\n",
       "            (geometric_dropout): Dropout(p=0.15, inplace=False)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder4): UnetrUpBlock(\n",
       "    (transp_conv): Convolution(\n",
       "      (conv): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "    )\n",
       "    (decoder_block): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): TransformerBlock(\n",
       "          (norm): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "          (ecd_block): ECD(\n",
       "            (content_kv): Linear(in_features=64, out_features=128, bias=False)\n",
       "            (semantic_query): Linear(in_features=64, out_features=64, bias=False)\n",
       "            (geometric_query): Linear(in_features=16, out_features=16, bias=False)\n",
       "            (semantic_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            (semantic_projection): Linear(in_features=64, out_features=32, bias=True)\n",
       "            (geometric_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            (geometric_projection): Linear(in_features=64, out_features=32, bias=True)\n",
       "            (semantic_dropout): Dropout(p=0.15, inplace=False)\n",
       "            (geometric_dropout): Dropout(p=0.15, inplace=False)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (norm): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "          (ecd_block): ECD(\n",
       "            (content_kv): Linear(in_features=64, out_features=128, bias=False)\n",
       "            (semantic_query): Linear(in_features=64, out_features=64, bias=False)\n",
       "            (geometric_query): Linear(in_features=16, out_features=16, bias=False)\n",
       "            (semantic_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            (semantic_projection): Linear(in_features=64, out_features=32, bias=True)\n",
       "            (geometric_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            (geometric_projection): Linear(in_features=64, out_features=32, bias=True)\n",
       "            (semantic_dropout): Dropout(p=0.15, inplace=False)\n",
       "            (geometric_dropout): Dropout(p=0.15, inplace=False)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (norm): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "          (ecd_block): ECD(\n",
       "            (content_kv): Linear(in_features=64, out_features=128, bias=False)\n",
       "            (semantic_query): Linear(in_features=64, out_features=64, bias=False)\n",
       "            (geometric_query): Linear(in_features=16, out_features=16, bias=False)\n",
       "            (semantic_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            (semantic_projection): Linear(in_features=64, out_features=32, bias=True)\n",
       "            (geometric_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            (geometric_projection): Linear(in_features=64, out_features=32, bias=True)\n",
       "            (semantic_dropout): Dropout(p=0.15, inplace=False)\n",
       "            (geometric_dropout): Dropout(p=0.15, inplace=False)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder3): UnetrUpBlock(\n",
       "    (transp_conv): Convolution(\n",
       "      (conv): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "    )\n",
       "    (decoder_block): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): TransformerBlock(\n",
       "          (norm): GroupNorm(1, 32, eps=1e-05, affine=True)\n",
       "          (ecd_block): ECD(\n",
       "            (content_kv): Linear(in_features=32, out_features=64, bias=False)\n",
       "            (semantic_query): Linear(in_features=32, out_features=32, bias=False)\n",
       "            (geometric_query): Linear(in_features=32, out_features=32, bias=False)\n",
       "            (semantic_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "            (semantic_projection): Linear(in_features=32, out_features=16, bias=True)\n",
       "            (geometric_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "            (geometric_projection): Linear(in_features=32, out_features=16, bias=True)\n",
       "            (semantic_dropout): Dropout(p=0.15, inplace=False)\n",
       "            (geometric_dropout): Dropout(p=0.15, inplace=False)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(32, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (norm): GroupNorm(1, 32, eps=1e-05, affine=True)\n",
       "          (ecd_block): ECD(\n",
       "            (content_kv): Linear(in_features=32, out_features=64, bias=False)\n",
       "            (semantic_query): Linear(in_features=32, out_features=32, bias=False)\n",
       "            (geometric_query): Linear(in_features=32, out_features=32, bias=False)\n",
       "            (semantic_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "            (semantic_projection): Linear(in_features=32, out_features=16, bias=True)\n",
       "            (geometric_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "            (geometric_projection): Linear(in_features=32, out_features=16, bias=True)\n",
       "            (semantic_dropout): Dropout(p=0.15, inplace=False)\n",
       "            (geometric_dropout): Dropout(p=0.15, inplace=False)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(32, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (norm): GroupNorm(1, 32, eps=1e-05, affine=True)\n",
       "          (ecd_block): ECD(\n",
       "            (content_kv): Linear(in_features=32, out_features=64, bias=False)\n",
       "            (semantic_query): Linear(in_features=32, out_features=32, bias=False)\n",
       "            (geometric_query): Linear(in_features=32, out_features=32, bias=False)\n",
       "            (semantic_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "            (semantic_projection): Linear(in_features=32, out_features=16, bias=True)\n",
       "            (geometric_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "            (geometric_projection): Linear(in_features=32, out_features=16, bias=True)\n",
       "            (semantic_dropout): Dropout(p=0.15, inplace=False)\n",
       "            (geometric_dropout): Dropout(p=0.15, inplace=False)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(32, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder2): UnetrUpBlock(\n",
       "    (transp_conv): Convolution(\n",
       "      (conv): ConvTranspose3d(32, 16, kernel_size=(2, 4, 4), stride=(2, 4, 4), bias=False)\n",
       "    )\n",
       "    (decoder_block): ModuleList(\n",
       "      (0): UnetResBlock(\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (norm1): InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (norm2): InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out1): UnetOutBlock(\n",
       "    (conv): Convolution(\n",
       "      (conv): Conv3d(16, 14, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    )\n",
       "  )\n",
       "  (out2): UnetOutBlock(\n",
       "    (conv): Convolution(\n",
       "      (conv): Conv3d(32, 14, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    )\n",
       "  )\n",
       "  (out3): UnetOutBlock(\n",
       "    (conv): Convolution(\n",
       "      (conv): Conv3d(64, 14, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34ad3f96-2f73-4929-9e80-5e5fe07b178d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume shape: (64, 64, 64)\n",
      "Number of patches: 512\n",
      "Sequence length: 512\n",
      "\n",
      "=== FLOP Comparison ===\n",
      "Standard Attention FLOPs: 402,653,184 (0.40B)\n",
      "Local Head FLOPs: 100,663,296 (100.7M)\n",
      "Regional Head FLOPs: 1,572,864 (1.6M)\n",
      "Global Head FLOPs: 150,994,944 (151.0M)\n",
      "Cross-slice Head FLOPs: 1,572,864 (1572.9K)\n",
      "\n",
      "Total Hydra FLOPs: 254,803,968 (254.8M)\n",
      "Speedup: 1.6x\n",
      "Memory reduction: ~1.6x\n",
      "Calculated num_patches: 512\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LocalBoundaryHead' object has no attribute 'patch_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 394\u001b[0m\n\u001b[1;32m    391\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(batch_size, num_patches, \u001b[38;5;241m768\u001b[39m)\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 394\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvolume_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mInput shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[2], line 68\u001b[0m, in \u001b[0;36mEfficient3DHydraAttention.forward\u001b[0;34m(self, x, volume_shape, mask)\u001b[0m\n\u001b[1;32m     65\u001b[0m cross_weight \u001b[38;5;241m=\u001b[39m routing_scores[:, :, \u001b[38;5;241m3\u001b[39m:\u001b[38;5;241m4\u001b[39m]      \u001b[38;5;66;03m# [B, N, 1]\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Apply each hydra head with adaptive weighting\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m local_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocal_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvolume_shape\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m local_weight\n\u001b[1;32m     69\u001b[0m regional_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregional_head(x, volume_shape) \u001b[38;5;241m*\u001b[39m regional_weight\n\u001b[1;32m     70\u001b[0m global_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglobal_head(x, volume_shape) \u001b[38;5;241m*\u001b[39m global_weight\n",
      "File \u001b[0;32m~/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[2], line 98\u001b[0m, in \u001b[0;36mLocalBoundaryHead.forward\u001b[0;34m(self, x, volume_shape)\u001b[0m\n\u001b[1;32m     95\u001b[0m D, H, W \u001b[38;5;241m=\u001b[39m volume_shape\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# Calculate patch dimensions\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m patch_d, patch_h, patch_w \u001b[38;5;241m=\u001b[39m D \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpatch_size\u001b[49m[\u001b[38;5;241m0\u001b[39m], H \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_size[\u001b[38;5;241m1\u001b[39m], W \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_size[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# Verify dimensions match\u001b[39;00m\n\u001b[1;32m    101\u001b[0m expected_patches \u001b[38;5;241m=\u001b[39m patch_d \u001b[38;5;241m*\u001b[39m patch_h \u001b[38;5;241m*\u001b[39m patch_w\n",
      "File \u001b[0;32m~/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/torch/nn/modules/module.py:1931\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1929\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1930\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1931\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1932\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1933\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LocalBoundaryHead' object has no attribute 'patch_size'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from typing import Tuple, Optional\n",
    "\n",
    "class Efficient3DHydraAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Memory-efficient Hydra Attention for 3D medical image segmentation\n",
    "    Combines multiple specialized attention heads with different computational patterns\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        embed_dim: int = 768,\n",
    "        num_heads: int = 12,\n",
    "        patch_size: Tuple[int, int, int] = (8, 8, 8),\n",
    "        window_sizes: Tuple[int, int, int] = (32, 64, 128),\n",
    "        dropout: float = 0.1,\n",
    "        use_flash_attention: bool = True\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "        self.scale = self.head_dim ** -0.5\n",
    "        self.patch_size = patch_size\n",
    "        self.window_sizes = window_sizes\n",
    "        self.use_flash_attention = use_flash_attention\n",
    "        \n",
    "        # Hydra Heads - each specialized for different tasks\n",
    "        self.local_head = LocalBoundaryHead(embed_dim, num_heads // 4, dropout)\n",
    "        self.regional_head = RegionalContextHead(embed_dim, num_heads // 4, dropout)\n",
    "        self.global_head = GlobalAnatomyHead(embed_dim, num_heads // 4, dropout)\n",
    "        self.cross_slice_head = CrossSliceHead(embed_dim, num_heads // 4, dropout)\n",
    "        \n",
    "        # Adaptive routing - learns which tokens go to which head\n",
    "        self.routing_gate = nn.Linear(embed_dim, 4)\n",
    "        \n",
    "        # Output projection\n",
    "        self.out_proj = nn.Linear(embed_dim, embed_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(\n",
    "        self, \n",
    "        x: torch.Tensor, \n",
    "        volume_shape: Tuple[int, int, int],\n",
    "        mask: Optional[torch.Tensor] = None\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input tensor [B, N, C] where N = D*H*W patches\n",
    "            volume_shape: Original 3D volume dimensions (D, H, W)\n",
    "            mask: Optional attention mask\n",
    "        \"\"\"\n",
    "        B, N, C = x.shape\n",
    "        \n",
    "        # Adaptive routing - decide which tokens need which type of attention\n",
    "        routing_scores = F.softmax(self.routing_gate(x), dim=-1)  # [B, N, 4]\n",
    "        \n",
    "        # Split routing scores for each head\n",
    "        local_weight = routing_scores[:, :, 0:1]      # [B, N, 1]\n",
    "        regional_weight = routing_scores[:, :, 1:2]   # [B, N, 1]\n",
    "        global_weight = routing_scores[:, :, 2:3]     # [B, N, 1]\n",
    "        cross_weight = routing_scores[:, :, 3:4]      # [B, N, 1]\n",
    "        \n",
    "        # Apply each hydra head with adaptive weighting\n",
    "        local_out = self.local_head(x, volume_shape) * local_weight\n",
    "        regional_out = self.regional_head(x, volume_shape) * regional_weight\n",
    "        global_out = self.global_head(x, volume_shape) * global_weight\n",
    "        cross_out = self.cross_slice_head(x, volume_shape) * cross_weight\n",
    "        \n",
    "        # Combine outputs\n",
    "        hydra_out = local_out + regional_out + global_out + cross_out\n",
    "        \n",
    "        # Final projection\n",
    "        out = self.out_proj(hydra_out)\n",
    "        return self.dropout(out)\n",
    "\n",
    "\n",
    "class LocalBoundaryHead(nn.Module):\n",
    "    \"\"\"Focuses on fine-grained boundaries and edges\"\"\"\n",
    "    \n",
    "    def __init__(self, embed_dim: int, num_heads: int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = embed_dim // (num_heads * 4)  # Smaller head for efficiency\n",
    "        self.scale = self.head_dim ** -0.5\n",
    "        \n",
    "        self.qkv = nn.Linear(embed_dim, self.head_dim * num_heads * 3)\n",
    "        self.window_size = 8  # Small local window\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, volume_shape: Tuple[int, int, int]) -> torch.Tensor:\n",
    "        B, N, C = x.shape\n",
    "        D, H, W = volume_shape\n",
    "        \n",
    "        # Calculate patch dimensions\n",
    "        patch_d, patch_h, patch_w = D // self.patch_size[0], H // self.patch_size[1], W // self.patch_size[2]\n",
    "        \n",
    "        # Verify dimensions match\n",
    "        expected_patches = patch_d * patch_h * patch_w\n",
    "        if N != expected_patches:\n",
    "            raise ValueError(f\"Expected {expected_patches} patches, got {N}\")\n",
    "        \n",
    "        # Reshape to 3D grid of patches\n",
    "        x_3d = x.view(B, patch_d, patch_h, patch_w, C)\n",
    "        \n",
    "        # Apply windowed attention - process small 2x2x2 windows of patches\n",
    "        return self._windowed_attention_3d(x_3d, 2).view(B, N, -1)  # Use 2x2x2 windows of patches\n",
    "    \n",
    "    def _windowed_attention_3d(self, x: torch.Tensor, window_size: int) -> torch.Tensor:\n",
    "        B, patch_D, patch_H, patch_W, C = x.shape\n",
    "        \n",
    "        # Pad if necessary to make divisible by window_size\n",
    "        pad_d = (window_size - patch_D % window_size) % window_size\n",
    "        pad_h = (window_size - patch_H % window_size) % window_size  \n",
    "        pad_w = (window_size - patch_W % window_size) % window_size\n",
    "        \n",
    "        if pad_d > 0 or pad_h > 0 or pad_w > 0:\n",
    "            x = F.pad(x, (0, 0, 0, pad_w, 0, pad_h, 0, pad_d))\n",
    "        \n",
    "        patch_D, patch_H, patch_W = x.shape[1:4]\n",
    "        \n",
    "        # Create windows of patches\n",
    "        x = x.view(B, patch_D//window_size, window_size, patch_H//window_size, window_size, \n",
    "                  patch_W//window_size, window_size, C)\n",
    "        x = x.permute(0, 1, 3, 5, 2, 4, 6, 7).contiguous()\n",
    "        x = x.view(-1, window_size**3, C)\n",
    "        \n",
    "        # Apply attention within each window\n",
    "        qkv = self.qkv(x).reshape(-1, window_size**3, 3, self.num_heads, self.head_dim)\n",
    "        qkv = qkv.permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
    "        \n",
    "        # Efficient attention computation\n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
    "        attn = F.softmax(attn, dim=-1)\n",
    "        out = (attn @ v).transpose(1, 2).reshape(-1, window_size**3, self.num_heads * self.head_dim)\n",
    "        \n",
    "        # Reshape back\n",
    "        num_windows = (patch_D//window_size) * (patch_H//window_size) * (patch_W//window_size)\n",
    "        out = out.view(B, num_windows, window_size**3, -1)\n",
    "        out = out.view(B, patch_D//window_size, patch_H//window_size, patch_W//window_size,\n",
    "                      window_size, window_size, window_size, -1)\n",
    "        out = out.permute(0, 1, 4, 2, 5, 3, 6, 7).contiguous()\n",
    "        out = out.view(B, patch_D, patch_H, patch_W, -1)\n",
    "        \n",
    "        # Remove padding\n",
    "        original_D = patch_D - pad_d\n",
    "        original_H = patch_H - pad_h  \n",
    "        original_W = patch_W - pad_w\n",
    "        if pad_d > 0 or pad_h > 0 or pad_w > 0:\n",
    "            out = out[:, :original_D, :original_H, :original_W, :]\n",
    "            \n",
    "        return out\n",
    "\n",
    "\n",
    "class RegionalContextHead(nn.Module):\n",
    "    \"\"\"Focuses on organ-level structures with medium-range attention\"\"\"\n",
    "    \n",
    "    def __init__(self, embed_dim: int, num_heads: int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = embed_dim // (num_heads * 4)\n",
    "        self.scale = self.head_dim ** -0.5\n",
    "        \n",
    "        self.qkv = nn.Linear(embed_dim, self.head_dim * num_heads * 3)\n",
    "        self.stride = 2  # Strided attention for efficiency\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, volume_shape: Tuple[int, int, int]) -> torch.Tensor:\n",
    "        B, N, C = x.shape\n",
    "        \n",
    "        # Downsample for efficiency (every 2nd token in each dimension)\n",
    "        indices = self._get_strided_indices(volume_shape, self.stride)\n",
    "        x_strided = x[:, indices, :]  # [B, N//8, C]\n",
    "        \n",
    "        # Apply standard attention on downsampled tokens\n",
    "        qkv = self.qkv(x_strided).reshape(B, -1, 3, self.num_heads, self.head_dim)\n",
    "        qkv = qkv.permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
    "        \n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
    "        attn = F.softmax(attn, dim=-1)\n",
    "        out_strided = (attn @ v).transpose(1, 2).reshape(B, -1, self.num_heads * self.head_dim)\n",
    "        \n",
    "        # Upsample back to original size\n",
    "        out = self._upsample_to_original(out_strided, indices, N)\n",
    "        return out\n",
    "    \n",
    "    def _get_strided_indices(self, volume_shape: Tuple[int, int, int], stride: int) -> torch.Tensor:\n",
    "        D, H, W = volume_shape\n",
    "        # Convert to patch grid dimensions\n",
    "        patch_d, patch_h, patch_w = D // 8, H // 8, W // 8  # Assuming patch_size = (8,8,8)\n",
    "        \n",
    "        indices = []\n",
    "        for d in range(0, patch_d, stride):\n",
    "            for h in range(0, patch_h, stride):\n",
    "                for w in range(0, patch_w, stride):\n",
    "                    indices.append(d * patch_h * patch_w + h * patch_w + w)\n",
    "        return torch.tensor(indices, dtype=torch.long)\n",
    "    \n",
    "    def _upsample_to_original(self, x_strided: torch.Tensor, indices: torch.Tensor, original_N: int) -> torch.Tensor:\n",
    "        B, _, C = x_strided.shape\n",
    "        device = x_strided.device\n",
    "        \n",
    "        # Create output tensor\n",
    "        out = torch.zeros(B, original_N, C, device=device)\n",
    "        \n",
    "        # Fill strided positions\n",
    "        out[:, indices, :] = x_strided\n",
    "        \n",
    "        # Simple interpolation for missing positions (could be more sophisticated)\n",
    "        mask = torch.zeros(original_N, dtype=torch.bool, device=device)\n",
    "        mask[indices] = True\n",
    "        \n",
    "        # Linear interpolation for empty positions\n",
    "        for i in range(original_N):\n",
    "            if not mask[i]:\n",
    "                # Find nearest filled positions\n",
    "                left_idx = indices[indices < i].max() if len(indices[indices < i]) > 0 else indices[0]\n",
    "                right_idx = indices[indices > i].min() if len(indices[indices > i]) > 0 else indices[-1]\n",
    "                \n",
    "                # Simple average (could use distance weighting)\n",
    "                out[:, i, :] = (out[:, left_idx, :] + out[:, right_idx, :]) / 2\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "class GlobalAnatomyHead(nn.Module):\n",
    "    \"\"\"Captures global anatomical relationships with linear attention\"\"\"\n",
    "    \n",
    "    def __init__(self, embed_dim: int, num_heads: int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = embed_dim // (num_heads * 4)\n",
    "        \n",
    "        # Linear attention for O(N) complexity\n",
    "        self.to_q = nn.Linear(embed_dim, self.head_dim * num_heads)\n",
    "        self.to_k = nn.Linear(embed_dim, self.head_dim * num_heads)\n",
    "        self.to_v = nn.Linear(embed_dim, self.head_dim * num_heads)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, volume_shape: Tuple[int, int, int]) -> torch.Tensor:\n",
    "        B, N, C = x.shape\n",
    "        \n",
    "        q = self.to_q(x).view(B, N, self.num_heads, self.head_dim)\n",
    "        k = self.to_k(x).view(B, N, self.num_heads, self.head_dim)\n",
    "        v = self.to_v(x).view(B, N, self.num_heads, self.head_dim)\n",
    "        \n",
    "        # Linear attention: O(N) instead of O(N)\n",
    "        # Compute k^T @ v first, then q @ (k^T @ v)\n",
    "        kv = k.transpose(-2, -1) @ v  # [B, num_heads, head_dim, head_dim]\n",
    "        out = q @ kv  # [B, N, num_heads, head_dim]\n",
    "        \n",
    "        # Normalize\n",
    "        k_sum = k.sum(dim=1, keepdim=True)  # [B, 1, num_heads, head_dim]\n",
    "        normalizer = q @ k_sum.transpose(-2, -1)  # [B, N, num_heads, 1]\n",
    "        out = out / (normalizer + 1e-6)\n",
    "        \n",
    "        return out.reshape(B, N, -1)\n",
    "\n",
    "\n",
    "class CrossSliceHead(nn.Module):\n",
    "    \"\"\"Ensures consistency across different slice orientations\"\"\"\n",
    "    \n",
    "    def __init__(self, embed_dim: int, num_heads: int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = embed_dim // (num_heads * 4)\n",
    "        self.scale = self.head_dim ** -0.5\n",
    "        \n",
    "        self.qkv = nn.Linear(embed_dim, self.head_dim * num_heads * 3)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, volume_shape: Tuple[int, int, int]) -> torch.Tensor:\n",
    "        B, N, C = x.shape\n",
    "        D, H, W = volume_shape\n",
    "        \n",
    "        # Convert to patch grid dimensions\n",
    "        patch_d, patch_h, patch_w = D // 8, H // 8, W // 8  # Assuming patch_size = (8,8,8)\n",
    "        \n",
    "        # Reshape to 3D patch grid\n",
    "        x_3d = x.view(B, patch_d, patch_h, patch_w, C)\n",
    "        \n",
    "        # Sample representative slices from each orientation\n",
    "        # Axial (xy planes) - sample every few slices in depth\n",
    "        axial_step = max(1, patch_d // 4)\n",
    "        axial_slices = x_3d[:, ::axial_step, :, :, :].reshape(B, -1, C)\n",
    "        \n",
    "        # Sagittal (yz planes) - sample every few slices in height\n",
    "        sagittal_step = max(1, patch_h // 4)\n",
    "        sagittal_slices = x_3d[:, :, ::sagittal_step, :, :].reshape(B, -1, C)\n",
    "        \n",
    "        # Coronal (xz planes) - sample every few slices in width\n",
    "        coronal_step = max(1, patch_w // 4)\n",
    "        coronal_slices = x_3d[:, :, :, ::coronal_step, :].reshape(B, -1, C)\n",
    "        \n",
    "        # Combine all slice samples\n",
    "        slice_tokens = torch.cat([axial_slices, sagittal_slices, coronal_slices], dim=1)\n",
    "        \n",
    "        # Apply attention across slice samples\n",
    "        qkv = self.qkv(slice_tokens).reshape(B, -1, 3, self.num_heads, self.head_dim)\n",
    "        qkv = qkv.permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
    "        \n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
    "        attn = F.softmax(attn, dim=-1)\n",
    "        slice_out = (attn @ v).transpose(1, 2).reshape(B, -1, self.num_heads * self.head_dim)\n",
    "        \n",
    "        # Broadcast back to all positions (simplified - could be more sophisticated)\n",
    "        global_context = slice_out.mean(dim=1, keepdim=True)  # [B, 1, C]\n",
    "        out = global_context.expand(B, N, -1)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "# Example usage and efficiency comparison\n",
    "def compare_attention_efficiency():\n",
    "    \"\"\"Compare FLOP counts for different attention mechanisms\"\"\"\n",
    "    \n",
    "    # Typical 3D medical image parameters\n",
    "    batch_size = 2\n",
    "    volume_shape = (64, 64, 64)  # D, H, W\n",
    "    patch_size = (8, 8, 8)\n",
    "    embed_dim = 768\n",
    "    \n",
    "    # Calculate number of patches\n",
    "    num_patches = (volume_shape[0] // patch_size[0]) * \\\n",
    "                  (volume_shape[1] // patch_size[1]) * \\\n",
    "                  (volume_shape[2] // patch_size[2])\n",
    "    \n",
    "    print(f\"Volume shape: {volume_shape}\")\n",
    "    print(f\"Number of patches: {num_patches}\")\n",
    "    print(f\"Sequence length: {num_patches}\")\n",
    "    \n",
    "    # FLOP comparison\n",
    "    print(\"\\n=== FLOP Comparison ===\")\n",
    "    \n",
    "    # Standard attention: O(N)\n",
    "    standard_flops = 2 * num_patches * num_patches * embed_dim\n",
    "    print(f\"Standard Attention FLOPs: {standard_flops:,} ({standard_flops/1e9:.2f}B)\")\n",
    "    \n",
    "    # Hydra attention breakdown:\n",
    "    # Local head: windowed attention\n",
    "    window_size = 8\n",
    "    num_windows = num_patches // (window_size**3)\n",
    "    local_flops = 2 * num_windows * (window_size**3) * (window_size**3) * (embed_dim//4)\n",
    "    print(f\"Local Head FLOPs: {local_flops:,} ({local_flops/1e6:.1f}M)\")\n",
    "    \n",
    "    # Regional head: strided attention  \n",
    "    strided_patches = num_patches // 8  # stride=2 in each dim\n",
    "    regional_flops = 2 * strided_patches * strided_patches * (embed_dim//4)\n",
    "    print(f\"Regional Head FLOPs: {regional_flops:,} ({regional_flops/1e6:.1f}M)\")\n",
    "    \n",
    "    # Global head: linear attention\n",
    "    global_flops = 2 * num_patches * embed_dim * (embed_dim//4)  # O(N*d)\n",
    "    print(f\"Global Head FLOPs: {global_flops:,} ({global_flops/1e6:.1f}M)\")\n",
    "    \n",
    "    # Cross-slice head: sparse sampling\n",
    "    slice_samples = 64  # Representative slices\n",
    "    cross_flops = 2 * slice_samples * slice_samples * (embed_dim//4)\n",
    "    print(f\"Cross-slice Head FLOPs: {cross_flops:,} ({cross_flops/1e3:.1f}K)\")\n",
    "    \n",
    "    total_hydra_flops = local_flops + regional_flops + global_flops + cross_flops\n",
    "    print(f\"\\nTotal Hydra FLOPs: {total_hydra_flops:,} ({total_hydra_flops/1e6:.1f}M)\")\n",
    "    print(f\"Speedup: {standard_flops/total_hydra_flops:.1f}x\")\n",
    "    print(f\"Memory reduction: ~{standard_flops/total_hydra_flops:.1f}x\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Test the implementation\n",
    "    compare_attention_efficiency()\n",
    "    \n",
    "    # Create model\n",
    "    model = Efficient3DHydraAttention(\n",
    "        embed_dim=768,\n",
    "        num_heads=12,\n",
    "        patch_size=(8, 8, 8),\n",
    "        dropout=0.1\n",
    "    )\n",
    "    \n",
    "    # Test forward pass\n",
    "    batch_size = 2\n",
    "    volume_shape = (64, 64, 64)\n",
    "    patch_size = (8, 8, 8)\n",
    "    \n",
    "    # Calculate correct number of patches\n",
    "    num_patches = (volume_shape[0] // patch_size[0]) * \\\n",
    "                  (volume_shape[1] // patch_size[1]) * \\\n",
    "                  (volume_shape[2] // patch_size[2])\n",
    "    print(f\"Calculated num_patches: {num_patches}\")\n",
    "    \n",
    "    x = torch.randn(batch_size, num_patches, 768)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(x, volume_shape)\n",
    "        print(f\"\\nInput shape: {x.shape}\")\n",
    "        print(f\"Output shape: {output.shape}\")\n",
    "        print(\" Forward pass successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97adbc4-45d8-444d-89b1-a210ab25a3a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
